{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'\n",
    "html = requests.get(url).content\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rob Dodson ( robdodson)',\n",
       " 'MichaIng)',\n",
       " 'Gleb Bahmutov ( bahmutov)',\n",
       " 'Lukas Taegert Atkinson ( lukastaegert)',\n",
       " 'Till Krüss ( tillkruss)',\n",
       " 'Jesse Duffield ( jesseduffield)',\n",
       " 'ᴜɴᴋɴᴡᴏɴ ( unknwon)',\n",
       " 'Arve Knudsen ( aknuds1)',\n",
       " 'Niklas von Hertzen ( niklasvh)',\n",
       " 'Stephen Celis ( stephencelis)',\n",
       " 'Damian Dulisz ( shentao)',\n",
       " 'Yufan You ( ouuan)',\n",
       " 'Christian Clauss ( cclauss)',\n",
       " 'Jirka Borovec ( Borda)',\n",
       " 'Timothy Edmund Crosley ( timothycrosley)',\n",
       " 'James Newton King ( JamesNK)',\n",
       " 'Michael Shilman ( shilman)',\n",
       " 'Mike Penz ( mikepenz)',\n",
       " 'Alex Hall ( alexmojaki)',\n",
       " 'Diego Sampaio ( sampaiodiego)',\n",
       " 'Dries Vints ( driesvints)',\n",
       " 'JK Jung ( jkjung avt)',\n",
       " 'Steven ( styfle)',\n",
       " 'Daniel Martí ( mvdan)',\n",
       " 'Łukasz Magiera ( magik6k)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "import re\n",
    "\n",
    "\n",
    "names2 = soup.find_all('div',{'class':'col-md-6'})\n",
    "list_names = [q.text for q in names2]\n",
    "names1 = [re.sub('\\W',' ', k) for k in list_names]\n",
    "names3 = names1[::2]\n",
    "names4 = [t[15:-2] for t in names3]\n",
    "names5 = [re.sub(' \\s',' (', z,1) for z in names4]\n",
    "names6 = [re.sub(' \\s','', z) for z in names5]\n",
    "names7 = [re.sub('\\s\\Z',')', t) for t in names6]\n",
    "\n",
    "names7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Go library for accessing the GitHub API ',\n",
       " ' Build interactivepublication quality documents from Jupyter Notebooks ',\n",
       " ' The Servo Browser Engine ',\n",
       " ' Open source live customer chat ',\n",
       " ' LeetCode刷题记录 ',\n",
       " ' Best Practicescode samplesand documentation for Computer Vision',\n",
       " ' DrogonA C14 17 based HTTP web application framework running on Linux macOS Unix Windows ',\n",
       " ' 一个涵盖六个专栏 Spring Boot 2 X Spring Cloud Spring Cloud Alibaba Dubbo 分布式消息队列 分布式事务的仓库 希望胖友小手一抖 右上角来个 Star 感恩 1024 ',\n",
       " ' The UI component explorerDevelopdocumenttest for ReactVueAngularEmberWeb Componentsmore',\n",
       " ' Hunt down social media accounts by username across social networks ',\n",
       " ' A set of tools that keep Java sweet',\n",
       " 'Android Pokedex using Dagger HiltMotionCoroutinesFlowJetpackRoomViewModelLiveDatabased on MVVM architecture',\n",
       " ' A list of commandsscriptsresourcesand more that I have gathered and attempted to consolidate for use as OSCPand morestudy materialCommands inUsefulcommandsKeepnoteBookmarks and reading material inBookmarkListCherryTreeReconscan Py2 and Py3Custom ISO building',\n",
       " 'GitHub中文排行榜 帮助你发现高分优秀中文项目 更高效地吸收国人的优秀经验成果 榜单每周更新一次 敬请关注',\n",
       " ' 大数据面试题 大数据成神之路开启 Flink Spark Hadoop Hbase Hive',\n",
       " ' 渗透测试有关的POC EXP 脚本 提权 小工具等 欢迎补充 完善 About penetration testing python script poc getshell csrf xss cms php getshell domainmod xss penetration testing poc csrf webshell cobub razor cve rce sql sql poc poc exp bypass oa getshell cve cms ',\n",
       " ' TypeScript is a superset of JavaScript that compiles to clean JavaScript output',\n",
       " ' Front end framework with a built in dark modedesigned for rapidly building beautiful dashboards and product pages',\n",
       " ' Laravel best practices ',\n",
       " ' A free video streaming service that runs on a ESP32 ',\n",
       " ' A stablizing reserve currency protocol ',\n",
       " ' Visual localization made easy',\n",
       " ' The easiest way to automate your data ',\n",
       " ' Draft of the fastai book ',\n",
       " ' One frameworkMobile desktop']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "\n",
    "url1 = 'https://github.com/trending'\n",
    "html1 = requests.get(url1).content\n",
    "soup1 = BeautifulSoup(html1, 'lxml')\n",
    "repos = soup1.find_all('p',{'class':'col-9 text-gray my-1 pr-4'})\n",
    "repos_names = [q.text for q in repos]\n",
    "repos_names2 = [re.sub('\\W',' ', t) for t in repos_names]\n",
    "repos_names3 = [re.sub(' \\s','',j)for j in repos_names2]\n",
    "repos_names3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Newman_Laugh-O-Gram_%281921%29.webm/220px-seek%3D2-Newman_Laugh-O-Gram_%281921%29.webm.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/7/71/Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg/170px-Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Disney_Display_Case.JPG/170px-Disney_Display_Case.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/4/44/The_Walt_Disney_Company_Logo.svg/120px-The_Walt_Disney_Company_Logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/30px-Animation_disc.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/29px-P_vip.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/24px-Magic_Kingdom_castle.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/30px-Video-x-generic.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/30px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/30px-Blank_television_set.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/30px-Flag_of_the_United_States.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/22px-Commons-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/25px-Wikiquote-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/30px-Wikidata-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " '/static/images/footer/wikimedia-button.png',\n",
       " '/static/images/footer/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "html2 = requests.get(url2).content\n",
    "soup2 = BeautifulSoup(html2, 'lxml')\n",
    "links = soup2.find_all('img')\n",
    "list_links = [ ]\n",
    "for k in links:\n",
    "    list_links.append(k.get('src'))\n",
    "list_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 ='https://en.wikipedia.org/wiki/Python' \n",
    "html3 = requests.get(url3).content\n",
    "soup3 = BeautifulSoup(html3, 'lxml')\n",
    "links1 = soup3.find_all('a')\n",
    "list_links1 = []\n",
    "for k in links1:\n",
    "    list_links1.append(k.get('href'))\n",
    "    \n",
    "# remove the \"none object:\"\n",
    "list_links2 = list(list_links1[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wiktionary.org/wiki/Python',\n",
       " 'https://en.wiktionary.org/wiki/python',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Python&namespace=0',\n",
       " 'https://en.wikipedia.org/w/index.php?title=Python&oldid=963092579',\n",
       " 'https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452',\n",
       " 'https://commons.wikimedia.org/wiki/Category:Python',\n",
       " 'https://af.wikipedia.org/wiki/Python',\n",
       " 'https://als.wikipedia.org/wiki/Python',\n",
       " 'https://ar.wikipedia.org/wiki/%D8%A8%D8%A7%D9%8A%D8%AB%D9%88%D9%86',\n",
       " 'https://az.wikipedia.org/wiki/Python',\n",
       " 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%BE%E0%A6%87%E0%A6%A5%E0%A6%A8_(%E0%A6%A6%E0%A7%8D%E0%A6%AC%E0%A7%8D%E0%A6%AF%E0%A6%B0%E0%A7%8D%E0%A6%A5%E0%A6%A4%E0%A6%BE_%E0%A6%A8%E0%A6%BF%E0%A6%B0%E0%A6%B8%E0%A6%A8)',\n",
       " 'https://be.wikipedia.org/wiki/Python',\n",
       " 'https://bg.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%BF%D0%BE%D1%8F%D1%81%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)',\n",
       " 'https://cs.wikipedia.org/wiki/Python_(rozcestn%C3%ADk)',\n",
       " 'https://da.wikipedia.org/wiki/Python',\n",
       " 'https://de.wikipedia.org/wiki/Python',\n",
       " 'https://eo.wikipedia.org/wiki/Pitono_(apartigilo)',\n",
       " 'https://eu.wikipedia.org/wiki/Python_(argipena)',\n",
       " 'https://fa.wikipedia.org/wiki/%D9%BE%D8%A7%DB%8C%D8%AA%D9%88%D9%86',\n",
       " 'https://fr.wikipedia.org/wiki/Python',\n",
       " 'https://ko.wikipedia.org/wiki/%ED%8C%8C%EC%9D%B4%EC%84%A0',\n",
       " 'https://hr.wikipedia.org/wiki/Python_(razdvojba)',\n",
       " 'https://io.wikipedia.org/wiki/Pitono',\n",
       " 'https://id.wikipedia.org/wiki/Python',\n",
       " 'https://ia.wikipedia.org/wiki/Python_(disambiguation)',\n",
       " 'https://is.wikipedia.org/wiki/Python_(a%C3%B0greining)',\n",
       " 'https://it.wikipedia.org/wiki/Python_(disambigua)',\n",
       " 'https://he.wikipedia.org/wiki/%D7%A4%D7%99%D7%AA%D7%95%D7%9F',\n",
       " 'https://ka.wikipedia.org/wiki/%E1%83%9E%E1%83%98%E1%83%97%E1%83%9D%E1%83%9C%E1%83%98_(%E1%83%9B%E1%83%A0%E1%83%90%E1%83%95%E1%83%90%E1%83%9A%E1%83%9B%E1%83%9C%E1%83%98%E1%83%A8%E1%83%95%E1%83%9C%E1%83%94%E1%83%9A%E1%83%9D%E1%83%95%E1%83%90%E1%83%9C%E1%83%98)',\n",
       " 'https://kg.wikipedia.org/wiki/Mboma_(nyoka)',\n",
       " 'https://la.wikipedia.org/wiki/Python_(discretiva)',\n",
       " 'https://lb.wikipedia.org/wiki/Python',\n",
       " 'https://hu.wikipedia.org/wiki/Python_(egy%C3%A9rtelm%C5%B1s%C3%ADt%C5%91_lap)',\n",
       " 'https://mr.wikipedia.org/wiki/%E0%A4%AA%E0%A4%BE%E0%A4%AF%E0%A4%A5%E0%A5%89%E0%A4%A8_(%E0%A4%86%E0%A4%9C%E0%A5%8D%E0%A4%9E%E0%A4%BE%E0%A4%B5%E0%A4%B2%E0%A5%80_%E0%A4%AD%E0%A4%BE%E0%A4%B7%E0%A4%BE)',\n",
       " 'https://nl.wikipedia.org/wiki/Python',\n",
       " 'https://ja.wikipedia.org/wiki/%E3%83%91%E3%82%A4%E3%82%BD%E3%83%B3',\n",
       " 'https://no.wikipedia.org/wiki/Pyton',\n",
       " 'https://pl.wikipedia.org/wiki/Pyton',\n",
       " 'https://pt.wikipedia.org/wiki/Python_(desambigua%C3%A7%C3%A3o)',\n",
       " 'https://ru.wikipedia.org/wiki/Python_(%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F)',\n",
       " 'https://sk.wikipedia.org/wiki/Python',\n",
       " 'https://sr.wikipedia.org/wiki/%D0%9F%D0%B8%D1%82%D0%BE%D0%BD_(%D0%B2%D0%B8%D1%88%D0%B5%D0%B7%D0%BD%D0%B0%D1%87%D0%BD%D0%B0_%D0%BE%D0%B4%D1%80%D0%B5%D0%B4%D0%BD%D0%B8%D1%86%D0%B0)',\n",
       " 'https://sh.wikipedia.org/wiki/Python',\n",
       " 'https://fi.wikipedia.org/wiki/Python',\n",
       " 'https://sv.wikipedia.org/wiki/Pyton',\n",
       " 'https://th.wikipedia.org/wiki/%E0%B9%84%E0%B8%9E%E0%B8%97%E0%B8%AD%E0%B8%99',\n",
       " 'https://tr.wikipedia.org/wiki/Python',\n",
       " 'https://uk.wikipedia.org/wiki/%D0%9F%D1%96%D1%84%D0%BE%D0%BD',\n",
       " 'https://ur.wikipedia.org/wiki/%D9%BE%D8%A7%D8%A6%DB%8C%D8%AA%DA%BE%D9%88%D9%86',\n",
       " 'https://vi.wikipedia.org/wiki/Python',\n",
       " 'https://zh.wikipedia.org/wiki/Python_(%E6%B6%88%E6%AD%A7%E4%B9%89)',\n",
       " 'https://www.wikidata.org/wiki/Special:EntityPage/Q747452#sitelinks-wikipedia',\n",
       " 'https://foundation.wikimedia.org/wiki/Privacy_policy',\n",
       " 'https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute',\n",
       " 'https://stats.wikimedia.org/#/en.wikipedia.org',\n",
       " 'https://foundation.wikimedia.org/wiki/Cookie_statement',\n",
       " 'https://wikimediafoundation.org/',\n",
       " 'https://www.mediawiki.org/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "list_links3 = []\n",
    "for k in list_links2:\n",
    "    if k[:5] == 'https':\n",
    "        list_links3.append(k)\n",
    "    else:\n",
    "        pass\n",
    "list_links3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of titles that have changed in the United States Code since its last release point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 titles have been changed\n",
      "\n",
      "\n",
      "          Title 5 - Government Organization and Employees ٭\n",
      "\n",
      "\n",
      "\n",
      "          Title 8 - Aliens and Nationality\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "          Title 22 - Foreign Relations and Intercourse\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "          Title 34 - Crime Control and Law Enforcement\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "          Title 38 - Veterans' Benefits ٭\n",
      "\n",
      "\n",
      "\n",
      "          Title 47 - Telecommunications\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "          Title 54 - National Park Service and Related Programs ٭\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url4 = 'http://uscode.house.gov/download/download.shtml'\n",
    "html4 = requests.get(url4).content\n",
    "soup4 = BeautifulSoup(html4, 'lxml')\n",
    "titles = soup4.find_all('div',{'class':'usctitlechanged'})\n",
    "print(len(titles), 'titles have been changed')\n",
    "for k in titles:\n",
    "    print(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a Python list with the top ten FBI's Most Wanted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ALEXIS FLORES ',\n",
       " ' EUGENE PALMER ',\n",
       " ' RAFAEL CARO QUINTERO ',\n",
       " ' ROBERT WILLIAM FISHER ',\n",
       " ' BHADRESHKUMAR CHETANBHAI PATEL ',\n",
       " ' ALEJANDRO ROSALES CASTILLO ',\n",
       " ' ARNOLDO JIMENEZ ',\n",
       " ' JASON DEREK BROWN ',\n",
       " ' YASER ABDEL SAID ',\n",
       " ' SANTIAGO VILLALBA MEDEROS ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url5 = 'https://www.fbi.gov/wanted/topten'\n",
    "html5 = requests.get(url5).content\n",
    "soup5 = BeautifulSoup(html5, 'lxml')\n",
    "list_FBI = soup5.find_all('h3',{'class':'title'})\n",
    "list_names_FBI = [q.text for q in list_FBI]\n",
    "list_names_FBI2 = [re.sub('\\W',' ', t) for t in list_names_FBI]\n",
    "list_names_FBI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date & Time UTC',\n",
       " 'Latitude degrees',\n",
       " 'Longitude degrees',\n",
       " 'Depth km',\n",
       " 'Mag  [+]',\n",
       " 'Region name  [+]',\n",
       " 'Last update [-]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://www.emsc-csem.org/Earthquake/'\n",
    "html6 = requests.get(url6).content\n",
    "soup6 = BeautifulSoup(html6, 'lxml')\n",
    "title_table = soup6.find_all('th',{'class':'th2'})\n",
    "title = []\n",
    "list_ti = [tr.text for tr in title_table]\n",
    "list_title = list_ti[1:]\n",
    "list_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time_UTC</th>\n",
       "      <th>Latitude_degrees</th>\n",
       "      <th>Longitude_degrees</th>\n",
       "      <th>Depth_km</th>\n",
       "      <th>Mag</th>\n",
       "      <th>Region_name</th>\n",
       "      <th>Last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-15 16:30:45.011min ago</td>\n",
       "      <td>9.44S</td>\n",
       "      <td>113.95E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.7</td>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>2020-08-15 16:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-15 15:45:50.056min ago</td>\n",
       "      <td>19.17N</td>\n",
       "      <td>155.47W</td>\n",
       "      <td>34</td>\n",
       "      <td>Ml2.6</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-08-15 15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-15 15:36:34.11hr 05min ago</td>\n",
       "      <td>3.96S</td>\n",
       "      <td>80.93W</td>\n",
       "      <td>40</td>\n",
       "      <td>mb4.4</td>\n",
       "      <td>PERU-ECUADOR BORDER REGION</td>\n",
       "      <td>2020-08-15 16:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-15 15:26:26.01hr 15min ago</td>\n",
       "      <td>9.35S</td>\n",
       "      <td>113.91E</td>\n",
       "      <td>25</td>\n",
       "      <td>M2.9</td>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>2020-08-15 15:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-15 15:22:16.01hr 19min ago</td>\n",
       "      <td>9.82S</td>\n",
       "      <td>119.00E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.6</td>\n",
       "      <td>SUMBA REGION, INDONESIA</td>\n",
       "      <td>2020-08-15 15:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-08-15 15:08:30.01hr 33min ago</td>\n",
       "      <td>8.73N</td>\n",
       "      <td>83.09W</td>\n",
       "      <td>23</td>\n",
       "      <td>M3.2</td>\n",
       "      <td>COSTA RICA</td>\n",
       "      <td>2020-08-15 15:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-08-15 15:07:02.01hr 34min ago</td>\n",
       "      <td>23.31S</td>\n",
       "      <td>69.06W</td>\n",
       "      <td>95</td>\n",
       "      <td>ML3.8</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "      <td>2020-08-15 15:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-15 14:58:36.01hr 43min ago</td>\n",
       "      <td>9.78S</td>\n",
       "      <td>119.03E</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.0</td>\n",
       "      <td>SUMBA REGION, INDONESIA</td>\n",
       "      <td>2020-08-15 15:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-08-15 14:42:56.01hr 59min ago</td>\n",
       "      <td>2.11S</td>\n",
       "      <td>134.04E</td>\n",
       "      <td>14</td>\n",
       "      <td>M4.1</td>\n",
       "      <td>NEAR N COAST OF PAPUA, INDONESIA</td>\n",
       "      <td>2020-08-15 14:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-08-15 14:39:29.02hr 02min ago</td>\n",
       "      <td>2.20S</td>\n",
       "      <td>134.05E</td>\n",
       "      <td>17</td>\n",
       "      <td>M3.4</td>\n",
       "      <td>NEAR N COAST OF PAPUA, INDONESIA</td>\n",
       "      <td>2020-08-15 14:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-08-15 14:30:47.02hr 11min ago</td>\n",
       "      <td>33.21S</td>\n",
       "      <td>70.06W</td>\n",
       "      <td>13</td>\n",
       "      <td>ML3.3</td>\n",
       "      <td>MENDOZA, ARGENTINA</td>\n",
       "      <td>2020-08-15 14:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-08-15 14:26:48.02hr 15min ago</td>\n",
       "      <td>9.50S</td>\n",
       "      <td>114.05E</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.3</td>\n",
       "      <td>SOUTH OF BALI, INDONESIA</td>\n",
       "      <td>2020-08-15 14:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-08-15 14:20:30.02hr 21min ago</td>\n",
       "      <td>8.38N</td>\n",
       "      <td>82.88W</td>\n",
       "      <td>26</td>\n",
       "      <td>M3.3</td>\n",
       "      <td>PANAMA-COSTA RICA BORDER REGION</td>\n",
       "      <td>2020-08-15 14:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-08-15 14:02:09.22hr 39min ago</td>\n",
       "      <td>19.23N</td>\n",
       "      <td>155.39W</td>\n",
       "      <td>32</td>\n",
       "      <td>Ml2.5</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-08-15 14:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-08-15 13:59:55.02hr 42min ago</td>\n",
       "      <td>8.90S</td>\n",
       "      <td>122.10E</td>\n",
       "      <td>31</td>\n",
       "      <td>M2.5</td>\n",
       "      <td>FLORES REGION, INDONESIA</td>\n",
       "      <td>2020-08-15 14:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-08-15 13:38:22.03hr 03min ago</td>\n",
       "      <td>0.72S</td>\n",
       "      <td>123.45E</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.9</td>\n",
       "      <td>SULAWESI, INDONESIA</td>\n",
       "      <td>2020-08-15 13:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-08-15 13:37:20.03hr 04min ago</td>\n",
       "      <td>9.33S</td>\n",
       "      <td>114.06E</td>\n",
       "      <td>23</td>\n",
       "      <td>M2.9</td>\n",
       "      <td>SOUTH OF BALI, INDONESIA</td>\n",
       "      <td>2020-08-15 13:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-08-15 13:35:46.03hr 06min ago</td>\n",
       "      <td>0.67N</td>\n",
       "      <td>125.08E</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.3</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "      <td>2020-08-15 13:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-08-15 13:25:09.03hr 16min ago</td>\n",
       "      <td>3.08S</td>\n",
       "      <td>130.72E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.9</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2020-08-15 13:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-08-15 13:00:36.03hr 41min ago</td>\n",
       "      <td>10.11N</td>\n",
       "      <td>123.24E</td>\n",
       "      <td>12</td>\n",
       "      <td>M3.0</td>\n",
       "      <td>NEGROS- CEBU REG, PHILIPPINES</td>\n",
       "      <td>2020-08-15 13:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-08-15 12:54:50.13hr 47min ago</td>\n",
       "      <td>45.73N</td>\n",
       "      <td>26.77E</td>\n",
       "      <td>96</td>\n",
       "      <td>ML2.9</td>\n",
       "      <td>ROMANIA</td>\n",
       "      <td>2020-08-15 14:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-08-15 12:50:10.63hr 51min ago</td>\n",
       "      <td>35.83N</td>\n",
       "      <td>97.98W</td>\n",
       "      <td>3</td>\n",
       "      <td>ML2.2</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>2020-08-15 12:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-08-15 12:32:54.64hr 09min ago</td>\n",
       "      <td>19.93S</td>\n",
       "      <td>69.21W</td>\n",
       "      <td>100</td>\n",
       "      <td>mb4.5</td>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "      <td>2020-08-15 13:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-08-15 12:28:41.44hr 13min ago</td>\n",
       "      <td>44.35N</td>\n",
       "      <td>115.22W</td>\n",
       "      <td>14</td>\n",
       "      <td>Ml2.1</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>2020-08-15 14:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-08-15 12:20:44.04hr 21min ago</td>\n",
       "      <td>9.39S</td>\n",
       "      <td>114.09E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.6</td>\n",
       "      <td>SOUTH OF BALI, INDONESIA</td>\n",
       "      <td>2020-08-15 12:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-08-15 12:19:37.04hr 22min ago</td>\n",
       "      <td>15.99N</td>\n",
       "      <td>95.16W</td>\n",
       "      <td>10</td>\n",
       "      <td>M4.0</td>\n",
       "      <td>OFFSHORE OAXACA, MEXICO</td>\n",
       "      <td>2020-08-15 12:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-08-15 12:13:58.04hr 28min ago</td>\n",
       "      <td>33.22S</td>\n",
       "      <td>70.06W</td>\n",
       "      <td>16</td>\n",
       "      <td>ML3.4</td>\n",
       "      <td>MENDOZA, ARGENTINA</td>\n",
       "      <td>2020-08-15 12:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-08-15 12:10:21.04hr 31min ago</td>\n",
       "      <td>7.22S</td>\n",
       "      <td>143.29E</td>\n",
       "      <td>10</td>\n",
       "      <td>M4.8</td>\n",
       "      <td>NEAR S COAST OF NEW GUINEA, PNG.</td>\n",
       "      <td>2020-08-15 12:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-08-15 12:08:03.24hr 33min ago</td>\n",
       "      <td>36.13N</td>\n",
       "      <td>117.91W</td>\n",
       "      <td>4</td>\n",
       "      <td>Ml2.3</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2020-08-15 12:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-08-15 12:04:44.04hr 37min ago</td>\n",
       "      <td>22.66S</td>\n",
       "      <td>70.55W</td>\n",
       "      <td>9</td>\n",
       "      <td>ML2.5</td>\n",
       "      <td>OFFSHORE ANTOFAGASTA, CHILE</td>\n",
       "      <td>2020-08-15 12:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-08-15 12:04:30.04hr 37min ago</td>\n",
       "      <td>9.22S</td>\n",
       "      <td>114.17E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.7</td>\n",
       "      <td>SOUTH OF BALI, INDONESIA</td>\n",
       "      <td>2020-08-15 12:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-08-15 12:01:21.34hr 40min ago</td>\n",
       "      <td>17.88N</td>\n",
       "      <td>66.97W</td>\n",
       "      <td>10</td>\n",
       "      <td>ML2.7</td>\n",
       "      <td>PUERTO RICO REGION</td>\n",
       "      <td>2020-08-15 12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-08-15 11:52:04.24hr 49min ago</td>\n",
       "      <td>35.66N</td>\n",
       "      <td>117.49W</td>\n",
       "      <td>3</td>\n",
       "      <td>Ml2.0</td>\n",
       "      <td>SOUTHERN CALIFORNIA</td>\n",
       "      <td>2020-08-15 11:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-08-15 11:24:10.05hr 17min ago</td>\n",
       "      <td>10.22S</td>\n",
       "      <td>124.14E</td>\n",
       "      <td>15</td>\n",
       "      <td>M3.2</td>\n",
       "      <td>TIMOR REGION, INDONESIA</td>\n",
       "      <td>2020-08-15 11:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-08-15 11:11:57.85hr 30min ago</td>\n",
       "      <td>33.23S</td>\n",
       "      <td>70.11W</td>\n",
       "      <td>2</td>\n",
       "      <td>Mw4.8</td>\n",
       "      <td>REGION METROPOLITANA, CHILE</td>\n",
       "      <td>2020-08-15 12:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-08-15 11:11:13.05hr 30min ago</td>\n",
       "      <td>5.47S</td>\n",
       "      <td>133.88E</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.0</td>\n",
       "      <td>KEPULAUAN KAI, INDONESIA</td>\n",
       "      <td>2020-08-15 11:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-08-15 10:53:18.25hr 48min ago</td>\n",
       "      <td>4.67N</td>\n",
       "      <td>125.55E</td>\n",
       "      <td>148</td>\n",
       "      <td>Mw4.9</td>\n",
       "      <td>KEPULAUAN SANGIHE, INDONESIA</td>\n",
       "      <td>2020-08-15 11:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-08-15 10:48:40.45hr 53min ago</td>\n",
       "      <td>22.84S</td>\n",
       "      <td>112.55W</td>\n",
       "      <td>10</td>\n",
       "      <td>mb5.0</td>\n",
       "      <td>EASTER ISLAND REGION</td>\n",
       "      <td>2020-08-15 14:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2020-08-15 10:44:00.05hr 58min ago</td>\n",
       "      <td>9.40S</td>\n",
       "      <td>113.98E</td>\n",
       "      <td>10</td>\n",
       "      <td>M4.0</td>\n",
       "      <td>SOUTH OF JAVA, INDONESIA</td>\n",
       "      <td>2020-08-15 10:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2020-08-15 10:39:39.96hr 02min ago</td>\n",
       "      <td>44.36N</td>\n",
       "      <td>115.20W</td>\n",
       "      <td>13</td>\n",
       "      <td>Ml3.0</td>\n",
       "      <td>SOUTHERN IDAHO</td>\n",
       "      <td>2020-08-15 13:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-08-15 10:28:00.06hr 14min ago</td>\n",
       "      <td>18.32N</td>\n",
       "      <td>71.78W</td>\n",
       "      <td>30</td>\n",
       "      <td>M3.1</td>\n",
       "      <td>HAITI REGION</td>\n",
       "      <td>2020-08-15 10:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-08-15 10:22:35.06hr 19min ago</td>\n",
       "      <td>18.13N</td>\n",
       "      <td>71.71W</td>\n",
       "      <td>44</td>\n",
       "      <td>M2.5</td>\n",
       "      <td>DOMINICAN REPUBLIC</td>\n",
       "      <td>2020-08-15 10:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-08-15 10:22:30.06hr 19min ago</td>\n",
       "      <td>27.80N</td>\n",
       "      <td>87.62E</td>\n",
       "      <td>10</td>\n",
       "      <td>M4.2</td>\n",
       "      <td>NEPAL</td>\n",
       "      <td>2020-08-15 10:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-08-15 10:08:20.06hr 33min ago</td>\n",
       "      <td>3.09S</td>\n",
       "      <td>130.69E</td>\n",
       "      <td>10</td>\n",
       "      <td>M3.5</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2020-08-15 10:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-08-15 10:06:38.96hr 35min ago</td>\n",
       "      <td>19.37N</td>\n",
       "      <td>155.28W</td>\n",
       "      <td>29</td>\n",
       "      <td>Md2.1</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2020-08-15 10:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-08-15 10:05:08.06hr 36min ago</td>\n",
       "      <td>9.30S</td>\n",
       "      <td>114.15E</td>\n",
       "      <td>10</td>\n",
       "      <td>M2.9</td>\n",
       "      <td>SOUTH OF BALI, INDONESIA</td>\n",
       "      <td>2020-08-15 10:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2020-08-15 09:59:09.06hr 42min ago</td>\n",
       "      <td>15.60N</td>\n",
       "      <td>93.50W</td>\n",
       "      <td>89</td>\n",
       "      <td>M3.8</td>\n",
       "      <td>OFFSHORE CHIAPAS, MEXICO</td>\n",
       "      <td>2020-08-15 13:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2020-08-15 09:56:12.06hr 45min ago</td>\n",
       "      <td>16.09N</td>\n",
       "      <td>96.97W</td>\n",
       "      <td>21</td>\n",
       "      <td>M3.2</td>\n",
       "      <td>OAXACA, MEXICO</td>\n",
       "      <td>2020-08-15 13:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-08-15 09:41:50.27hr 00min ago</td>\n",
       "      <td>37.67N</td>\n",
       "      <td>21.29E</td>\n",
       "      <td>17</td>\n",
       "      <td>ML3.1</td>\n",
       "      <td>SOUTHERN GREECE</td>\n",
       "      <td>2020-08-15 12:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-08-15 09:34:29.07hr 07min ago</td>\n",
       "      <td>18.88N</td>\n",
       "      <td>104.36W</td>\n",
       "      <td>3</td>\n",
       "      <td>M3.4</td>\n",
       "      <td>OFFSHORE COLIMA, MEXICO</td>\n",
       "      <td>2020-08-15 13:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»12345678910»</td>\n",
       "      <td>12345678910»12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "      <td>12345678910»</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date_Time_UTC            Latitude_degrees  \\\n",
       "0       2020-08-15 16:30:45.011min ago                       9.44S   \n",
       "1       2020-08-15 15:45:50.056min ago                      19.17N   \n",
       "2   2020-08-15 15:36:34.11hr 05min ago                       3.96S   \n",
       "3   2020-08-15 15:26:26.01hr 15min ago                       9.35S   \n",
       "4   2020-08-15 15:22:16.01hr 19min ago                       9.82S   \n",
       "5   2020-08-15 15:08:30.01hr 33min ago                       8.73N   \n",
       "6   2020-08-15 15:07:02.01hr 34min ago                      23.31S   \n",
       "7   2020-08-15 14:58:36.01hr 43min ago                       9.78S   \n",
       "8   2020-08-15 14:42:56.01hr 59min ago                       2.11S   \n",
       "9   2020-08-15 14:39:29.02hr 02min ago                       2.20S   \n",
       "10  2020-08-15 14:30:47.02hr 11min ago                      33.21S   \n",
       "11  2020-08-15 14:26:48.02hr 15min ago                       9.50S   \n",
       "12  2020-08-15 14:20:30.02hr 21min ago                       8.38N   \n",
       "13  2020-08-15 14:02:09.22hr 39min ago                      19.23N   \n",
       "14  2020-08-15 13:59:55.02hr 42min ago                       8.90S   \n",
       "15  2020-08-15 13:38:22.03hr 03min ago                       0.72S   \n",
       "16  2020-08-15 13:37:20.03hr 04min ago                       9.33S   \n",
       "17  2020-08-15 13:35:46.03hr 06min ago                       0.67N   \n",
       "18  2020-08-15 13:25:09.03hr 16min ago                       3.08S   \n",
       "19  2020-08-15 13:00:36.03hr 41min ago                      10.11N   \n",
       "20  2020-08-15 12:54:50.13hr 47min ago                      45.73N   \n",
       "21  2020-08-15 12:50:10.63hr 51min ago                      35.83N   \n",
       "22  2020-08-15 12:32:54.64hr 09min ago                      19.93S   \n",
       "23  2020-08-15 12:28:41.44hr 13min ago                      44.35N   \n",
       "24  2020-08-15 12:20:44.04hr 21min ago                       9.39S   \n",
       "25  2020-08-15 12:19:37.04hr 22min ago                      15.99N   \n",
       "26  2020-08-15 12:13:58.04hr 28min ago                      33.22S   \n",
       "27  2020-08-15 12:10:21.04hr 31min ago                       7.22S   \n",
       "28  2020-08-15 12:08:03.24hr 33min ago                      36.13N   \n",
       "29  2020-08-15 12:04:44.04hr 37min ago                      22.66S   \n",
       "30  2020-08-15 12:04:30.04hr 37min ago                       9.22S   \n",
       "31  2020-08-15 12:01:21.34hr 40min ago                      17.88N   \n",
       "32  2020-08-15 11:52:04.24hr 49min ago                      35.66N   \n",
       "33  2020-08-15 11:24:10.05hr 17min ago                      10.22S   \n",
       "34  2020-08-15 11:11:57.85hr 30min ago                      33.23S   \n",
       "35  2020-08-15 11:11:13.05hr 30min ago                       5.47S   \n",
       "36  2020-08-15 10:53:18.25hr 48min ago                       4.67N   \n",
       "37  2020-08-15 10:48:40.45hr 53min ago                      22.84S   \n",
       "38  2020-08-15 10:44:00.05hr 58min ago                       9.40S   \n",
       "39  2020-08-15 10:39:39.96hr 02min ago                      44.36N   \n",
       "40  2020-08-15 10:28:00.06hr 14min ago                      18.32N   \n",
       "41  2020-08-15 10:22:35.06hr 19min ago                      18.13N   \n",
       "42  2020-08-15 10:22:30.06hr 19min ago                      27.80N   \n",
       "43  2020-08-15 10:08:20.06hr 33min ago                       3.09S   \n",
       "44  2020-08-15 10:06:38.96hr 35min ago                      19.37N   \n",
       "45  2020-08-15 10:05:08.06hr 36min ago                       9.30S   \n",
       "46  2020-08-15 09:59:09.06hr 42min ago                      15.60N   \n",
       "47  2020-08-15 09:56:12.06hr 45min ago                      16.09N   \n",
       "48  2020-08-15 09:41:50.27hr 00min ago                      37.67N   \n",
       "49  2020-08-15 09:34:29.07hr 07min ago                      18.88N   \n",
       "50                                 NaN                         NaN   \n",
       "51                       12345678910»  12345678910»12345678910»   \n",
       "52                                 NaN                         NaN   \n",
       "\n",
       "             Longitude_degrees       Depth_km                         Mag  \\\n",
       "0                      113.95E             10                        M2.7   \n",
       "1                      155.47W             34                       Ml2.6   \n",
       "2                       80.93W             40                       mb4.4   \n",
       "3                      113.91E             25                        M2.9   \n",
       "4                      119.00E             10                        M2.6   \n",
       "5                       83.09W             23                        M3.2   \n",
       "6                       69.06W             95                       ML3.8   \n",
       "7                      119.03E             10                        M3.0   \n",
       "8                      134.04E             14                        M4.1   \n",
       "9                      134.05E             17                        M3.4   \n",
       "10                      70.06W             13                       ML3.3   \n",
       "11                     114.05E             10                        M3.3   \n",
       "12                      82.88W             26                        M3.3   \n",
       "13                     155.39W             32                       Ml2.5   \n",
       "14                     122.10E             31                        M2.5   \n",
       "15                     123.45E             10                        M3.9   \n",
       "16                     114.06E             23                        M2.9   \n",
       "17                     125.08E             10                        M3.3   \n",
       "18                     130.72E             10                        M2.9   \n",
       "19                     123.24E             12                        M3.0   \n",
       "20                      26.77E             96                       ML2.9   \n",
       "21                      97.98W              3                       ML2.2   \n",
       "22                      69.21W            100                       mb4.5   \n",
       "23                     115.22W             14                       Ml2.1   \n",
       "24                     114.09E             10                        M2.6   \n",
       "25                      95.16W             10                        M4.0   \n",
       "26                      70.06W             16                       ML3.4   \n",
       "27                     143.29E             10                        M4.8   \n",
       "28                     117.91W              4                       Ml2.3   \n",
       "29                      70.55W              9                       ML2.5   \n",
       "30                     114.17E             10                        M2.7   \n",
       "31                      66.97W             10                       ML2.7   \n",
       "32                     117.49W              3                       Ml2.0   \n",
       "33                     124.14E             15                        M3.2   \n",
       "34                      70.11W              2                       Mw4.8   \n",
       "35                     133.88E             10                        M3.0   \n",
       "36                     125.55E            148                       Mw4.9   \n",
       "37                     112.55W             10                       mb5.0   \n",
       "38                     113.98E             10                        M4.0   \n",
       "39                     115.20W             13                       Ml3.0   \n",
       "40                      71.78W             30                        M3.1   \n",
       "41                      71.71W             44                        M2.5   \n",
       "42                      87.62E             10                        M4.2   \n",
       "43                     130.69E             10                        M3.5   \n",
       "44                     155.28W             29                       Md2.1   \n",
       "45                     114.15E             10                        M2.9   \n",
       "46                      93.50W             89                        M3.8   \n",
       "47                      96.97W             21                        M3.2   \n",
       "48                      21.29E             17                       ML3.1   \n",
       "49                     104.36W              3                        M3.4   \n",
       "50                         NaN            NaN                         NaN   \n",
       "51  12345678910»12345678910»  12345678910»  12345678910»12345678910»   \n",
       "52                         NaN            NaN                         NaN   \n",
       "\n",
       "                         Region_name       Last_update  \n",
       "0           SOUTH OF JAVA, INDONESIA  2020-08-15 16:41  \n",
       "1           ISLAND OF HAWAII, HAWAII  2020-08-15 15:51  \n",
       "2         PERU-ECUADOR BORDER REGION  2020-08-15 16:13  \n",
       "3           SOUTH OF JAVA, INDONESIA  2020-08-15 15:47  \n",
       "4            SUMBA REGION, INDONESIA  2020-08-15 15:47  \n",
       "5                         COSTA RICA  2020-08-15 15:25  \n",
       "6                 ANTOFAGASTA, CHILE  2020-08-15 15:26  \n",
       "7            SUMBA REGION, INDONESIA  2020-08-15 15:07  \n",
       "8   NEAR N COAST OF PAPUA, INDONESIA  2020-08-15 14:57  \n",
       "9   NEAR N COAST OF PAPUA, INDONESIA  2020-08-15 14:50  \n",
       "10                MENDOZA, ARGENTINA  2020-08-15 14:53  \n",
       "11          SOUTH OF BALI, INDONESIA  2020-08-15 14:35  \n",
       "12   PANAMA-COSTA RICA BORDER REGION  2020-08-15 14:35  \n",
       "13          ISLAND OF HAWAII, HAWAII  2020-08-15 14:07  \n",
       "14          FLORES REGION, INDONESIA  2020-08-15 14:05  \n",
       "15               SULAWESI, INDONESIA  2020-08-15 13:46  \n",
       "16          SOUTH OF BALI, INDONESIA  2020-08-15 13:47  \n",
       "17                       MOLUCCA SEA  2020-08-15 13:40  \n",
       "18                  SERAM, INDONESIA  2020-08-15 13:40  \n",
       "19     NEGROS- CEBU REG, PHILIPPINES  2020-08-15 13:21  \n",
       "20                           ROMANIA  2020-08-15 14:53  \n",
       "21                          OKLAHOMA  2020-08-15 12:56  \n",
       "22                   TARAPACA, CHILE  2020-08-15 13:03  \n",
       "23                    SOUTHERN IDAHO  2020-08-15 14:48  \n",
       "24          SOUTH OF BALI, INDONESIA  2020-08-15 12:30  \n",
       "25           OFFSHORE OAXACA, MEXICO  2020-08-15 12:31  \n",
       "26                MENDOZA, ARGENTINA  2020-08-15 12:33  \n",
       "27  NEAR S COAST OF NEW GUINEA, PNG.  2020-08-15 12:31  \n",
       "28                CENTRAL CALIFORNIA  2020-08-15 12:11  \n",
       "29       OFFSHORE ANTOFAGASTA, CHILE  2020-08-15 12:19  \n",
       "30          SOUTH OF BALI, INDONESIA  2020-08-15 12:31  \n",
       "31                PUERTO RICO REGION  2020-08-15 12:14  \n",
       "32               SOUTHERN CALIFORNIA  2020-08-15 11:55  \n",
       "33           TIMOR REGION, INDONESIA  2020-08-15 11:40  \n",
       "34       REGION METROPOLITANA, CHILE  2020-08-15 12:49  \n",
       "35          KEPULAUAN KAI, INDONESIA  2020-08-15 11:31  \n",
       "36      KEPULAUAN SANGIHE, INDONESIA  2020-08-15 11:15  \n",
       "37              EASTER ISLAND REGION  2020-08-15 14:12  \n",
       "38          SOUTH OF JAVA, INDONESIA  2020-08-15 10:56  \n",
       "39                    SOUTHERN IDAHO  2020-08-15 13:57  \n",
       "40                      HAITI REGION  2020-08-15 10:50  \n",
       "41                DOMINICAN REPUBLIC  2020-08-15 10:40  \n",
       "42                             NEPAL  2020-08-15 10:40  \n",
       "43                  SERAM, INDONESIA  2020-08-15 10:17  \n",
       "44          ISLAND OF HAWAII, HAWAII  2020-08-15 10:09  \n",
       "45          SOUTH OF BALI, INDONESIA  2020-08-15 10:26  \n",
       "46          OFFSHORE CHIAPAS, MEXICO  2020-08-15 13:14  \n",
       "47                    OAXACA, MEXICO  2020-08-15 13:14  \n",
       "48                   SOUTHERN GREECE  2020-08-15 12:39  \n",
       "49           OFFSHORE COLIMA, MEXICO  2020-08-15 13:14  \n",
       "50                               NaN               NaN  \n",
       "51                     12345678910»     12345678910»  \n",
       "52                               NaN               NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df_list = pd.read_html(url6)\n",
    "df = df_list[3]\n",
    "df.columns = [r for r in range(13)]\n",
    "df = df[[3,4,5,6,7,8,9,10,11,12]]\n",
    "df = df.assign(Latitude_degrees = df[4] + df[5])\n",
    "df = df.assign(Longitude_degrees = df[6] + df[7])\n",
    "df = df.assign(Depth_km = df[8])\n",
    "df = df.assign(Mag = df[9]+df[10])\n",
    "df = df.assign(Region_name = df[11])\n",
    "df = df.assign(Last_update = df[12])\n",
    "df = df.assign(Date_Time_UTC = df[3])\n",
    "df = df[['Date_Time_UTC', 'Latitude_degrees', 'Longitude_degrees', 'Depth_km','Mag', 'Region_name','Last_update']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of tweets by a given Twitter account.\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account\n",
    "Ask the user for the handle (@handle) of a twitter account. You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the top 10 languages by number of native speakers stored in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IH_env]",
   "language": "python",
   "name": "conda-env-IH_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
